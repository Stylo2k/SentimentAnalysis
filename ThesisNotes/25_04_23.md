Results: 

- All models really struggle with typos / misspellings.
- Words like costs or generally words that need context can be correctly predicted by the chatGPT.
Example: "costs" is a neutral term that doesn't inherently carry a positive or negative sentiment. The sentiment of a sentence that includes the word "costs" would depend on the context and the words surrounding it.
- chatGPT will also provide the reason for the prediction.
- not aware of technical terms like "dynamodb"
- weird "The sentiment of the sentence is negative because "more cheaper" is grammatically incorrect."


----


- chatGPT output put into another small model llama, alpaca.
- prepare dataset using chatGPT and then manually check it. After that, train the model.
  - chatGPT is just for reason and sentiment.
- test using software engineering models, SentiCR 
  - measure the accuracy of the sentiment and reason.
  - compare the trained model with all the se models and the chatGPT model.
- how did others do this ?
- Issues and comments differently. 
  - title : skip
  - body : option: merge the title and the body
    - some take text and others take sentences.
  - What have they done for PR

talk to the study advisor and ask the boe.