Requirement already satisfied: pip in ./ownenv/lib/python3.10/site-packages (23.2)
Collecting git+https://github.com/huggingface/peft.git (from -r install.sh (line 10))
  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-13vs0u5a
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-13vs0u5a
  Resolved https://github.com/huggingface/peft.git to commit 029f416fced285fe72acd4e1be6c48067f7013d5
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting git+https://github.com/huggingface/transformers.git (from -r install.sh (line 11))
  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-fcnrjdj8
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-fcnrjdj8
  Resolved https://github.com/huggingface/transformers.git to commit 476be08c4aa96f8c1cae4200d2677bbe8f12cf80
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: accelerate==0.20.3 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 1)) (0.20.3)
Requirement already satisfied: appdirs==1.4.4 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 2)) (1.4.4)
Collecting bitsandbytes==0.37.2 (from -r install.sh (line 3))
  Using cached bitsandbytes-0.37.2-py3-none-any.whl (84.2 MB)
Requirement already satisfied: datasets==2.10.1 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 4)) (2.10.1)
Requirement already satisfied: fire==0.5.0 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 5)) (0.5.0)
Requirement already satisfied: torch==2.0.0 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 6)) (2.0.0)
Requirement already satisfied: sentencepiece==0.1.97 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 7)) (0.1.97)
Requirement already satisfied: tensorboardX==2.6 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 8)) (2.6)
Requirement already satisfied: gradio==3.23.0 in ./ownenv/lib/python3.10/site-packages (from -r install.sh (line 9)) (3.23.0)
Requirement already satisfied: numpy>=1.17 in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3->-r install.sh (line 1)) (1.25.1)
Requirement already satisfied: packaging>=20.0 in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3->-r install.sh (line 1)) (23.1)
Requirement already satisfied: psutil in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3->-r install.sh (line 1)) (5.9.5)
Requirement already satisfied: pyyaml in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3->-r install.sh (line 1)) (6.0.1)
Requirement already satisfied: pyarrow>=6.0.0 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (12.0.1)
Requirement already satisfied: dill<0.3.7,>=0.3.0 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (0.3.6)
Requirement already satisfied: pandas in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (2.0.3)
Requirement already satisfied: requests>=2.19.0 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (2.31.0)
Requirement already satisfied: tqdm>=4.62.1 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (4.65.0)
Requirement already satisfied: xxhash in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (3.2.0)
Requirement already satisfied: multiprocess in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (0.70.14)
Requirement already satisfied: fsspec[http]>=2021.11.1 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (2023.6.0)
Requirement already satisfied: aiohttp in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (3.8.4)
Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (0.16.4)
Requirement already satisfied: responses<0.19 in ./ownenv/lib/python3.10/site-packages (from datasets==2.10.1->-r install.sh (line 4)) (0.18.0)
Requirement already satisfied: six in ./ownenv/lib/python3.10/site-packages (from fire==0.5.0->-r install.sh (line 5)) (1.16.0)
Requirement already satisfied: termcolor in ./ownenv/lib/python3.10/site-packages (from fire==0.5.0->-r install.sh (line 5)) (2.3.0)
Requirement already satisfied: filelock in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (3.12.2)
Requirement already satisfied: typing-extensions in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (4.7.1)
Requirement already satisfied: sympy in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (1.12)
Requirement already satisfied: networkx in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (3.1)
Requirement already satisfied: jinja2 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.7.99)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (10.2.10.91)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.4.0.1)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.7.4.91)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (2.14.3)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (11.7.91)
Requirement already satisfied: triton==2.0.0 in ./ownenv/lib/python3.10/site-packages (from torch==2.0.0->-r install.sh (line 6)) (2.0.0)
Requirement already satisfied: protobuf<4,>=3.8.0 in ./ownenv/lib/python3.10/site-packages (from tensorboardX==2.6->-r install.sh (line 8)) (3.20.3)
Requirement already satisfied: aiofiles in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (23.1.0)
Requirement already satisfied: altair>=4.2.0 in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (5.0.1)
Requirement already satisfied: fastapi in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.100.0)
Requirement already satisfied: ffmpy in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.3.1)
Requirement already satisfied: httpx in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.24.1)
Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (2.2.0)
Requirement already satisfied: markupsafe in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (2.1.3)
Requirement already satisfied: matplotlib in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (3.7.2)
Requirement already satisfied: mdit-py-plugins<=0.3.3 in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.3.3)
Requirement already satisfied: orjson in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (3.9.2)
Requirement already satisfied: pillow in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (10.0.0)
Requirement already satisfied: pydantic in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (2.0.3)
Requirement already satisfied: pydub in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.25.1)
Requirement already satisfied: python-multipart in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.0.6)
Requirement already satisfied: semantic-version in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (2.10.0)
Requirement already satisfied: uvicorn in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (0.23.1)
Requirement already satisfied: websockets>=10.0 in ./ownenv/lib/python3.10/site-packages (from gradio==3.23.0->-r install.sh (line 9)) (11.0.3)
Requirement already satisfied: setuptools in ./ownenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r install.sh (line 6)) (68.0.0)
Requirement already satisfied: wheel in ./ownenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r install.sh (line 6)) (0.40.0)
Requirement already satisfied: cmake in ./ownenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->-r install.sh (line 6)) (3.26.4)
Requirement already satisfied: lit in ./ownenv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->-r install.sh (line 6)) (16.0.6)
Requirement already satisfied: safetensors in ./ownenv/lib/python3.10/site-packages (from peft==0.5.0.dev0->-r install.sh (line 10)) (0.3.1)
Requirement already satisfied: regex!=2019.12.17 in ./ownenv/lib/python3.10/site-packages (from transformers==4.32.0.dev0->-r install.sh (line 11)) (2023.6.3)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./ownenv/lib/python3.10/site-packages (from transformers==4.32.0.dev0->-r install.sh (line 11)) (0.13.3)
Requirement already satisfied: jsonschema>=3.0 in ./ownenv/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0->-r install.sh (line 9)) (4.18.4)
Requirement already satisfied: toolz in ./ownenv/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0->-r install.sh (line 9)) (0.12.0)
Requirement already satisfied: attrs>=17.3.0 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (23.1.0)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (3.2.0)
Requirement already satisfied: multidict<7.0,>=4.5 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (6.0.4)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (4.0.2)
Requirement already satisfied: yarl<2.0,>=1.0 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (1.9.2)
Requirement already satisfied: frozenlist>=1.1.1 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (1.4.0)
Requirement already satisfied: aiosignal>=1.1.2 in ./ownenv/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r install.sh (line 4)) (1.3.1)
Requirement already satisfied: mdurl~=0.1 in ./ownenv/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r install.sh (line 9)) (0.1.2)
Requirement already satisfied: linkify-it-py<3,>=1 in ./ownenv/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r install.sh (line 9)) (2.0.2)
Requirement already satisfied: python-dateutil>=2.8.2 in ./ownenv/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r install.sh (line 4)) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in ./ownenv/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r install.sh (line 4)) (2023.3)
Requirement already satisfied: tzdata>=2022.1 in ./ownenv/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r install.sh (line 4)) (2023.3)
Requirement already satisfied: idna<4,>=2.5 in ./ownenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r install.sh (line 4)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./ownenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r install.sh (line 4)) (2.0.3)
Requirement already satisfied: certifi>=2017.4.17 in ./ownenv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r install.sh (line 4)) (2023.5.7)
Requirement already satisfied: starlette<0.28.0,>=0.27.0 in ./ownenv/lib/python3.10/site-packages (from fastapi->gradio==3.23.0->-r install.sh (line 9)) (0.27.0)
Requirement already satisfied: annotated-types>=0.4.0 in ./ownenv/lib/python3.10/site-packages (from pydantic->gradio==3.23.0->-r install.sh (line 9)) (0.5.0)
Requirement already satisfied: pydantic-core==2.3.0 in ./ownenv/lib/python3.10/site-packages (from pydantic->gradio==3.23.0->-r install.sh (line 9)) (2.3.0)
Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in ./ownenv/lib/python3.10/site-packages (from httpx->gradio==3.23.0->-r install.sh (line 9)) (0.17.3)
Requirement already satisfied: sniffio in ./ownenv/lib/python3.10/site-packages (from httpx->gradio==3.23.0->-r install.sh (line 9)) (1.3.0)
Requirement already satisfied: contourpy>=1.0.1 in ./ownenv/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0->-r install.sh (line 9)) (1.1.0)
Requirement already satisfied: cycler>=0.10 in ./ownenv/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0->-r install.sh (line 9)) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in ./ownenv/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0->-r install.sh (line 9)) (4.41.0)
Requirement already satisfied: kiwisolver>=1.0.1 in ./ownenv/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0->-r install.sh (line 9)) (1.4.4)
Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./ownenv/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0->-r install.sh (line 9)) (3.0.9)
Requirement already satisfied: mpmath>=0.19 in ./ownenv/lib/python3.10/site-packages (from sympy->torch==2.0.0->-r install.sh (line 6)) (1.3.0)
Requirement already satisfied: click>=7.0 in ./ownenv/lib/python3.10/site-packages (from uvicorn->gradio==3.23.0->-r install.sh (line 9)) (8.1.6)
Requirement already satisfied: h11>=0.8 in ./ownenv/lib/python3.10/site-packages (from uvicorn->gradio==3.23.0->-r install.sh (line 9)) (0.14.0)
Requirement already satisfied: anyio<5.0,>=3.0 in ./ownenv/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0->-r install.sh (line 9)) (3.7.1)
Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./ownenv/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0->-r install.sh (line 9)) (2023.7.1)
Requirement already satisfied: referencing>=0.28.4 in ./ownenv/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0->-r install.sh (line 9)) (0.30.0)
Requirement already satisfied: rpds-py>=0.7.1 in ./ownenv/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0->-r install.sh (line 9)) (0.9.2)
Requirement already satisfied: uc-micro-py in ./ownenv/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0->-r install.sh (line 9)) (1.0.2)
Requirement already satisfied: exceptiongroup in ./ownenv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio==3.23.0->-r install.sh (line 9)) (1.1.2)
Installing collected packages: bitsandbytes
  Attempting uninstall: bitsandbytes
    Found existing installation: bitsandbytes 0.40.2
    Uninstalling bitsandbytes-0.40.2:
      Successfully uninstalled bitsandbytes-0.40.2
Successfully installed bitsandbytes-0.37.2
removing bitsandbytes
bitsandbytes
bitsandbytes-0.37.2.dist-info
installing bitsandbytes
Collecting bitsandbytes
  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/32/ea/75961538b08e4ed568057198717aabdebeaf6f398b7692420532e6861754/bitsandbytes-0.40.2-py3-none-any.whl.metadata
  Using cached bitsandbytes-0.40.2-py3-none-any.whl.metadata (9.8 kB)
Using cached bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)
Installing collected packages: bitsandbytes
Successfully installed bitsandbytes-0.40.2
bitsandbytes
bitsandbytes-0.40.2.dist-info
Requirement already satisfied: accelerate==0.20.3 in ./ownenv/lib/python3.10/site-packages (0.20.3)
Requirement already satisfied: numpy>=1.17 in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3) (1.25.1)
Requirement already satisfied: packaging>=20.0 in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3) (23.1)
Requirement already satisfied: psutil in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3) (5.9.5)
Requirement already satisfied: pyyaml in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3) (6.0.1)
Requirement already satisfied: torch>=1.6.0 in ./ownenv/lib/python3.10/site-packages (from accelerate==0.20.3) (2.0.0)
Requirement already satisfied: filelock in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.12.2)
Requirement already satisfied: typing-extensions in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.7.1)
Requirement already satisfied: sympy in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (1.12)
Requirement already satisfied: networkx in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1)
Requirement already satisfied: jinja2 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.99)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (10.2.10.91)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.4.0.1)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.4.91)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (2.14.3)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (11.7.91)
Requirement already satisfied: triton==2.0.0 in ./ownenv/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (2.0.0)
Requirement already satisfied: setuptools in ./ownenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.20.3) (68.0.0)
Requirement already satisfied: wheel in ./ownenv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.20.3) (0.40.0)
Requirement already satisfied: cmake in ./ownenv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (3.26.4)
Requirement already satisfied: lit in ./ownenv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (16.0.6)
Requirement already satisfied: MarkupSafe>=2.0 in ./ownenv/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.3)
Requirement already satisfied: mpmath>=0.19 in ./ownenv/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)
Requirement already satisfied: scipy in ./ownenv/lib/python3.10/site-packages (1.11.1)
Requirement already satisfied: numpy<1.28.0,>=1.21.6 in ./ownenv/lib/python3.10/site-packages (from scipy) (1.25.1)
==============================================
Running own_train.py
The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.
cuda
Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|â–Ž         | 1/33 [00:00<00:07,  4.08it/s]Loading checkpoint shards:   6%|â–Œ         | 2/33 [00:00<00:07,  4.36it/s]Loading checkpoint shards:   9%|â–‰         | 3/33 [00:00<00:06,  4.46it/s]Loading checkpoint shards:  12%|â–ˆâ–        | 4/33 [00:00<00:06,  4.51it/s]Loading checkpoint shards:  15%|â–ˆâ–Œ        | 5/33 [00:01<00:06,  4.56it/s]Loading checkpoint shards:  18%|â–ˆâ–Š        | 6/33 [00:01<00:05,  4.59it/s]Loading checkpoint shards:  21%|â–ˆâ–ˆ        | 7/33 [00:01<00:05,  4.60it/s]Loading checkpoint shards:  24%|â–ˆâ–ˆâ–       | 8/33 [00:01<00:05,  4.61it/s]Loading checkpoint shards:  27%|â–ˆâ–ˆâ–‹       | 9/33 [00:01<00:05,  4.63it/s]Loading checkpoint shards:  30%|â–ˆâ–ˆâ–ˆ       | 10/33 [00:02<00:04,  4.64it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 11/33 [00:02<00:04,  4.62it/s]Loading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 12/33 [00:02<00:04,  4.63it/s]Loading checkpoint shards:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 13/33 [00:02<00:04,  4.63it/s]Loading checkpoint shards:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/33 [00:03<00:04,  4.62it/s]Loading checkpoint shards:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 15/33 [00:03<00:03,  4.63it/s]Loading checkpoint shards:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 16/33 [00:03<00:03,  4.62it/s]Loading checkpoint shards:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:03<00:03,  4.62it/s]Loading checkpoint shards:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/33 [00:03<00:03,  4.61it/s]Loading checkpoint shards:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 19/33 [00:04<00:03,  4.62it/s]Loading checkpoint shards:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 20/33 [00:04<00:02,  4.61it/s]Loading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 21/33 [00:04<00:02,  4.62it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:04<00:02,  4.61it/s]Loading checkpoint shards:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:05<00:02,  4.63it/s]Loading checkpoint shards:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:05<00:01,  4.65it/s]Loading checkpoint shards:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:05<00:01,  4.65it/s]Loading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:05<00:01,  4.66it/s]Loading checkpoint shards:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:05<00:01,  4.66it/s]Loading checkpoint shards:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:06<00:01,  4.67it/s]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:06<00:00,  4.64it/s]Loading checkpoint shards:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:06<00:00,  4.65it/s]Loading checkpoint shards:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:06<00:00,  4.66it/s]Loading checkpoint shards:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:06<00:00,  4.51it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:07<00:00,  4.23it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:07<00:00,  4.56it/s]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. 
The class this function is called from is 'LlamaTokenizer'.
You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
Found cached dataset json (/home3/p306726/.cache/huggingface/datasets/json/default-ded5e9b5354d9bae/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 546.42it/s]
Loading cached split indices for dataset at /home3/p306726/.cache/huggingface/datasets/json/default-ded5e9b5354d9bae/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-334a4ef3dcaf8c53.arrow and /home3/p306726/.cache/huggingface/datasets/json/default-ded5e9b5354d9bae/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-1e838b6580317d83.arrow
Dataset({
    features: ['instruction', 'input', 'output'],
    num_rows: 1076
})
Map:   0%|          | 0/876 [00:00<?, ? examples/s]Map:  20%|â–ˆâ–ˆ        | 179/876 [00:00<00:00, 1758.22 examples/s]Map:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358/876 [00:00<00:00, 1761.70 examples/s]Map:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 536/876 [00:00<00:00, 1765.63 examples/s]Map:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 802/876 [00:00<00:00, 1761.86 examples/s]                                                               Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [00:00<00:00, 1857.82 examples/s]                                                               /home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
  0%|          | 0/300 [00:00<?, ?it/s]/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/300 [00:37<3:07:18, 37.59s/it]  1%|          | 2/300 [01:14<3:03:34, 36.96s/it]  1%|          | 3/300 [01:50<3:02:28, 36.86s/it]  1%|â–         | 4/300 [02:25<2:58:28, 36.18s/it]  2%|â–         | 5/300 [03:03<2:59:47, 36.57s/it]  2%|â–         | 6/300 [03:40<2:59:37, 36.66s/it]  2%|â–         | 7/300 [04:16<2:59:09, 36.69s/it]  3%|â–Ž         | 8/300 [04:52<2:57:36, 36.49s/it]  3%|â–Ž         | 9/300 [05:28<2:54:55, 36.07s/it]  3%|â–Ž         | 10/300 [06:01<2:51:07, 35.41s/it]                                                    3%|â–Ž         | 10/300 [06:01<2:51:07, 35.41s/it]  4%|â–Ž         | 11/300 [06:38<2:52:27, 35.81s/it]  4%|â–         | 12/300 [07:15<2:53:23, 36.12s/it]  4%|â–         | 13/300 [07:50<2:51:45, 35.91s/it]  5%|â–         | 14/300 [08:25<2:49:54, 35.64s/it]  5%|â–Œ         | 15/300 [09:01<2:49:22, 35.66s/it]  5%|â–Œ         | 16/300 [09:38<2:50:50, 36.09s/it]  6%|â–Œ         | 17/300 [10:14<2:49:07, 35.86s/it]  6%|â–Œ         | 18/300 [10:51<2:50:24, 36.26s/it]  6%|â–‹         | 19/300 [11:28<2:50:41, 36.45s/it]  7%|â–‹         | 20/300 [12:03<2:49:11, 36.26s/it]                                                    7%|â–‹         | 20/300 [12:03<2:49:11, 36.26s/it]  7%|â–‹         | 21/300 [12:39<2:47:15, 35.97s/it]  7%|â–‹         | 22/300 [13:18<2:50:47, 36.86s/it]  8%|â–Š         | 23/300 [13:55<2:51:15, 37.10s/it]  8%|â–Š         | 24/300 [14:29<2:45:16, 35.93s/it]  8%|â–Š         | 25/300 [15:05<2:45:45, 36.17s/it]  9%|â–Š         | 26/300 [15:40<2:43:22, 35.78s/it]  9%|â–‰         | 27/300 [16:17<2:43:50, 36.01s/it]  9%|â–‰         | 28/300 [16:52<2:41:48, 35.69s/it] 10%|â–‰         | 29/300 [17:28<2:42:25, 35.96s/it] 10%|â–ˆ         | 30/300 [18:04<2:41:13, 35.83s/it]                                                   10%|â–ˆ         | 30/300 [18:04<2:41:13, 35.83s/it] 10%|â–ˆ         | 31/300 [18:41<2:42:08, 36.16s/it] 11%|â–ˆ         | 32/300 [19:16<2:40:02, 35.83s/it] 11%|â–ˆ         | 33/300 [19:51<2:38:59, 35.73s/it] 11%|â–ˆâ–        | 34/300 [20:27<2:38:58, 35.86s/it] 12%|â–ˆâ–        | 35/300 [21:06<2:42:18, 36.75s/it] 12%|â–ˆâ–        | 36/300 [21:42<2:40:15, 36.42s/it] 12%|â–ˆâ–        | 37/300 [22:18<2:38:58, 36.27s/it] 13%|â–ˆâ–Ž        | 38/300 [22:54<2:37:43, 36.12s/it] 13%|â–ˆâ–Ž        | 39/300 [23:30<2:37:10, 36.13s/it] 13%|â–ˆâ–Ž        | 40/300 [24:05<2:35:57, 35.99s/it]                                                   13%|â–ˆâ–Ž        | 40/300 [24:05<2:35:57, 35.99s/it] 14%|â–ˆâ–Ž        | 41/300 [24:41<2:35:12, 35.96s/it] 14%|â–ˆâ–        | 42/300 [25:17<2:34:27, 35.92s/it] 14%|â–ˆâ–        | 43/300 [25:51<2:31:07, 35.28s/it] 15%|â–ˆâ–        | 44/300 [26:28<2:32:27, 35.73s/it] 15%|â–ˆâ–Œ        | 45/300 [27:04<2:32:39, 35.92s/it] 15%|â–ˆâ–Œ        | 46/300 [27:38<2:30:06, 35.46s/it] 16%|â–ˆâ–Œ        | 47/300 [28:15<2:31:00, 35.81s/it] 16%|â–ˆâ–Œ        | 48/300 [28:52<2:31:28, 36.07s/it] 16%|â–ˆâ–‹        | 49/300 [29:29<2:31:57, 36.32s/it] 17%|â–ˆâ–‹        | 50/300 [30:04<2:30:34, 36.14s/it]                                                   17%|â–ˆâ–‹        | 50/300 [30:04<2:30:34, 36.14s/it]{'loss': 3.4391, 'learning_rate': 2.9999999999999997e-05, 'epoch': 1.46}
{'loss': 3.2625, 'learning_rate': 5.9999999999999995e-05, 'epoch': 2.92}
{'loss': 2.8728, 'learning_rate': 8.999999999999999e-05, 'epoch': 4.38}
{'loss': 2.089, 'learning_rate': 0.00011399999999999999, 'epoch': 5.84}
{'loss': 1.5911, 'learning_rate': 0.00014099999999999998, 'epoch': 7.31}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.22it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.13it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:05,  3.94it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.89it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.48it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:05,  3.07it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:05,  2.85it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.93it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:02<00:04,  3.05it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:05,  2.79it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  2.61it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.80it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  2.92it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  2.81it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:03,  2.97it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.12it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.07it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:06<00:01,  3.03it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.14it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.19it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:07<00:01,  2.94it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.77it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  2.62it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.54it/s][A                                                  
                                               [A 17%|â–ˆâ–‹        | 50/300 [30:13<2:30:34, 36.14s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.54it/s][A
                                               [A/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 17%|â–ˆâ–‹        | 51/300 [30:50<2:41:22, 38.88s/it] 17%|â–ˆâ–‹        | 52/300 [31:25<2:36:32, 37.87s/it] 18%|â–ˆâ–Š        | 53/300 [32:00<2:32:27, 37.04s/it] 18%|â–ˆâ–Š        | 54/300 [32:35<2:29:08, 36.38s/it] 18%|â–ˆâ–Š        | 55/300 [33:12<2:28:40, 36.41s/it] 19%|â–ˆâ–Š        | 56/300 [33:46<2:25:38, 35.81s/it] 19%|â–ˆâ–‰        | 57/300 [34:22<2:25:40, 35.97s/it] 19%|â–ˆâ–‰        | 58/300 [34:59<2:25:59, 36.20s/it] 20%|â–ˆâ–‰        | 59/300 [35:35<2:24:40, 36.02s/it] 20%|â–ˆâ–ˆ        | 60/300 [36:10<2:23:35, 35.90s/it]                                                   20%|â–ˆâ–ˆ        | 60/300 [36:10<2:23:35, 35.90s/it] 20%|â–ˆâ–ˆ        | 61/300 [36:47<2:23:24, 36.00s/it] 21%|â–ˆâ–ˆ        | 62/300 [37:22<2:22:31, 35.93s/it] 21%|â–ˆâ–ˆ        | 63/300 [37:57<2:20:22, 35.54s/it] 21%|â–ˆâ–ˆâ–       | 64/300 [38:33<2:20:57, 35.84s/it] 22%|â–ˆâ–ˆâ–       | 65/300 [39:08<2:18:20, 35.32s/it] 22%|â–ˆâ–ˆâ–       | 66/300 [39:42<2:17:09, 35.17s/it] 22%|â–ˆâ–ˆâ–       | 67/300 [40:21<2:20:46, 36.25s/it] 23%|â–ˆâ–ˆâ–Ž       | 68/300 [40:58<2:20:18, 36.29s/it] 23%|â–ˆâ–ˆâ–Ž       | 69/300 [41:33<2:18:45, 36.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 70/300 [42:09<2:17:57, 35.99s/it]                                                   23%|â–ˆâ–ˆâ–Ž       | 70/300 [42:09<2:17:57, 35.99s/it] 24%|â–ˆâ–ˆâ–Ž       | 71/300 [42:43<2:15:12, 35.43s/it] 24%|â–ˆâ–ˆâ–       | 72/300 [43:19<2:15:23, 35.63s/it] 24%|â–ˆâ–ˆâ–       | 73/300 [43:57<2:17:24, 36.32s/it] 25%|â–ˆâ–ˆâ–       | 74/300 [44:34<2:17:28, 36.50s/it] 25%|â–ˆâ–ˆâ–Œ       | 75/300 [45:10<2:16:48, 36.48s/it] 25%|â–ˆâ–ˆâ–Œ       | 76/300 [45:46<2:15:33, 36.31s/it] 26%|â–ˆâ–ˆâ–Œ       | 77/300 [46:23<2:14:53, 36.29s/it] 26%|â–ˆâ–ˆâ–Œ       | 78/300 [47:02<2:17:23, 37.14s/it] 26%|â–ˆâ–ˆâ–‹       | 79/300 [47:37<2:15:10, 36.70s/it] 27%|â–ˆâ–ˆâ–‹       | 80/300 [48:13<2:12:59, 36.27s/it]                                                   27%|â–ˆâ–ˆâ–‹       | 80/300 [48:13<2:12:59, 36.27s/it] 27%|â–ˆâ–ˆâ–‹       | 81/300 [48:47<2:10:51, 35.85s/it] 27%|â–ˆâ–ˆâ–‹       | 82/300 [49:21<2:08:18, 35.32s/it] 28%|â–ˆâ–ˆâ–Š       | 83/300 [49:57<2:08:23, 35.50s/it] 28%|â–ˆâ–ˆâ–Š       | 84/300 [50:33<2:07:54, 35.53s/it] 28%|â–ˆâ–ˆâ–Š       | 85/300 [51:09<2:07:55, 35.70s/it] 29%|â–ˆâ–ˆâ–Š       | 86/300 [51:43<2:05:19, 35.14s/it] 29%|â–ˆâ–ˆâ–‰       | 87/300 [52:20<2:06:34, 35.65s/it] 29%|â–ˆâ–ˆâ–‰       | 88/300 [52:54<2:04:09, 35.14s/it] 30%|â–ˆâ–ˆâ–‰       | 89/300 [53:31<2:05:36, 35.72s/it] 30%|â–ˆâ–ˆâ–ˆ       | 90/300 [54:07<2:05:23, 35.83s/it]                                                   30%|â–ˆâ–ˆâ–ˆ       | 90/300 [54:07<2:05:23, 35.83s/it] 30%|â–ˆâ–ˆâ–ˆ       | 91/300 [54:44<2:05:42, 36.09s/it] 31%|â–ˆâ–ˆâ–ˆ       | 92/300 [55:20<2:05:31, 36.21s/it] 31%|â–ˆâ–ˆâ–ˆ       | 93/300 [55:56<2:04:37, 36.12s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 94/300 [56:33<2:04:54, 36.38s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 95/300 [57:08<2:02:47, 35.94s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 96/300 [57:44<2:02:06, 35.91s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 97/300 [58:20<2:01:38, 35.95s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 98/300 [58:55<2:00:17, 35.73s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 99/300 [59:29<1:57:59, 35.22s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 100/300 [1:00:04<1:57:17, 35.19s/it]                                                      33%|â–ˆâ–ˆâ–ˆâ–Ž      | 100/300 [1:00:04<1:57:17, 35.19s/it]{'eval_loss': 1.450406789779663, 'eval_runtime': 8.6693, 'eval_samples_per_second': 23.07, 'eval_steps_per_second': 2.884, 'epoch': 7.31}
{'loss': 1.3316, 'learning_rate': 0.00017099999999999998, 'epoch': 8.77}
{'loss': 1.1953, 'learning_rate': 0.000201, 'epoch': 10.23}
{'loss': 1.1553, 'learning_rate': 0.00023099999999999998, 'epoch': 11.69}
{'loss': 1.1116, 'learning_rate': 0.000261, 'epoch': 13.15}
{'loss': 1.074, 'learning_rate': 0.00029099999999999997, 'epoch': 14.61}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.29it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.15it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:01<00:05,  4.00it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.37it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.25it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:02<00:06,  2.87it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:06,  2.68it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.79it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:03<00:05,  2.96it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:05,  2.77it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:04<00:05,  2.56it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.70it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  2.77it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:05<00:03,  2.63it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:03,  2.82it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.00it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:06<00:02,  2.98it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:06<00:02,  2.97it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.12it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.16it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:07<00:01,  2.95it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.76it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:08<00:00,  2.49it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.42it/s][A                                                     
                                               [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 100/300 [1:00:13<1:57:17, 35.19s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.42it/s][A
                                               [A/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 101/300 [1:00:50<2:07:00, 38.29s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 102/300 [1:01:26<2:03:55, 37.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 103/300 [1:02:03<2:03:16, 37.54s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 104/300 [1:02:39<2:01:07, 37.08s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 105/300 [1:03:15<1:59:00, 36.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 106/300 [1:03:51<1:58:09, 36.54s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 107/300 [1:04:25<1:54:53, 35.72s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 108/300 [1:05:01<1:55:03, 35.96s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 109/300 [1:05:38<1:54:56, 36.11s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 110/300 [1:06:14<1:54:16, 36.09s/it]                                                      37%|â–ˆâ–ˆâ–ˆâ–‹      | 110/300 [1:06:14<1:54:16, 36.09s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 111/300 [1:06:50<1:53:36, 36.07s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 112/300 [1:07:26<1:53:09, 36.12s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 113/300 [1:08:02<1:52:27, 36.08s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 114/300 [1:08:39<1:52:43, 36.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 115/300 [1:09:15<1:52:13, 36.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 116/300 [1:09:51<1:50:41, 36.09s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 117/300 [1:10:27<1:50:14, 36.14s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 118/300 [1:11:03<1:49:48, 36.20s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 119/300 [1:11:38<1:48:05, 35.83s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 120/300 [1:12:14<1:47:05, 35.70s/it]                                                      40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 120/300 [1:12:14<1:47:05, 35.70s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 121/300 [1:12:49<1:45:35, 35.40s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 122/300 [1:13:27<1:47:19, 36.18s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 123/300 [1:14:01<1:45:33, 35.78s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 124/300 [1:14:35<1:42:43, 35.02s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 125/300 [1:15:11<1:43:12, 35.39s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 126/300 [1:15:47<1:43:06, 35.55s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 127/300 [1:16:22<1:42:09, 35.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 128/300 [1:16:57<1:41:28, 35.40s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 129/300 [1:17:34<1:42:06, 35.83s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 130/300 [1:18:11<1:42:34, 36.20s/it]                                                      43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 130/300 [1:18:11<1:42:34, 36.20s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 131/300 [1:18:47<1:42:00, 36.21s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 132/300 [1:19:23<1:41:04, 36.10s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 133/300 [1:19:58<1:39:37, 35.80s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 134/300 [1:20:33<1:38:03, 35.44s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 135/300 [1:21:09<1:37:41, 35.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 136/300 [1:21:45<1:38:03, 35.88s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 137/300 [1:22:22<1:37:46, 35.99s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 138/300 [1:22:57<1:36:58, 35.92s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 139/300 [1:23:34<1:36:36, 36.01s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 140/300 [1:24:09<1:35:31, 35.82s/it]                                                      47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 140/300 [1:24:09<1:35:31, 35.82s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 141/300 [1:24:45<1:34:46, 35.76s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 142/300 [1:25:20<1:33:53, 35.66s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 143/300 [1:25:56<1:33:38, 35.79s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 144/300 [1:26:32<1:33:10, 35.84s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 145/300 [1:27:09<1:33:27, 36.18s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 146/300 [1:27:44<1:31:39, 35.71s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 147/300 [1:28:21<1:31:58, 36.07s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 148/300 [1:28:55<1:30:28, 35.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 149/300 [1:29:30<1:28:56, 35.34s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 150/300 [1:30:08<1:30:37, 36.25s/it]                                                      50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 150/300 [1:30:08<1:30:37, 36.25s/it]{'eval_loss': 1.106642484664917, 'eval_runtime': 8.988, 'eval_samples_per_second': 22.252, 'eval_steps_per_second': 2.781, 'epoch': 14.61}
{'loss': 1.0525, 'learning_rate': 0.0002895, 'epoch': 16.07}
{'loss': 0.9963, 'learning_rate': 0.0002745, 'epoch': 17.53}
{'loss': 0.9421, 'learning_rate': 0.00025949999999999997, 'epoch': 19.0}
{'loss': 0.9097, 'learning_rate': 0.0002445, 'epoch': 20.46}
{'loss': 0.8689, 'learning_rate': 0.0002295, 'epoch': 21.92}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.27it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.14it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:05,  3.95it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.91it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.56it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:05,  3.08it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:05,  2.84it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.96it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:02<00:04,  3.14it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:04,  2.95it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  2.80it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.98it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  3.07it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  2.90it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:02,  3.03it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.14it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.03it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:06<00:02,  2.97it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.09it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.14it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:07<00:01,  2.92it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.77it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  2.63it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.55it/s][A                                                     
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 150/300 [1:30:17<1:30:37, 36.25s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.55it/s][A
                                               [A/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 151/300 [1:30:53<1:36:08, 38.72s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 152/300 [1:31:29<1:33:39, 37.97s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 153/300 [1:32:05<1:31:13, 37.23s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 154/300 [1:32:41<1:29:59, 36.99s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 155/300 [1:33:16<1:28:01, 36.43s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 156/300 [1:33:52<1:27:20, 36.40s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 157/300 [1:34:28<1:25:54, 36.05s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 158/300 [1:35:04<1:25:51, 36.28s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 159/300 [1:35:41<1:25:29, 36.38s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 160/300 [1:36:18<1:25:07, 36.48s/it]                                                      53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 160/300 [1:36:18<1:25:07, 36.48s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 161/300 [1:36:54<1:24:37, 36.53s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 162/300 [1:37:30<1:23:32, 36.32s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 163/300 [1:38:05<1:21:39, 35.76s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 164/300 [1:38:40<1:20:26, 35.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 165/300 [1:39:16<1:20:16, 35.68s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 166/300 [1:39:50<1:18:54, 35.33s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 167/300 [1:40:24<1:17:16, 34.86s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 168/300 [1:40:59<1:16:45, 34.89s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 169/300 [1:41:35<1:17:07, 35.33s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 170/300 [1:42:12<1:17:36, 35.82s/it]                                                      57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 170/300 [1:42:12<1:17:36, 35.82s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 171/300 [1:42:48<1:17:04, 35.85s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 172/300 [1:43:24<1:16:19, 35.78s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 173/300 [1:44:02<1:17:03, 36.40s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 174/300 [1:44:38<1:16:13, 36.30s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 175/300 [1:45:13<1:15:17, 36.14s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 176/300 [1:45:49<1:14:10, 35.89s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 177/300 [1:46:24<1:12:56, 35.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 178/300 [1:46:58<1:11:48, 35.31s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 179/300 [1:47:35<1:12:10, 35.79s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 180/300 [1:48:11<1:11:21, 35.68s/it]                                                      60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 180/300 [1:48:11<1:11:21, 35.68s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 181/300 [1:48:48<1:11:39, 36.13s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 182/300 [1:49:24<1:11:16, 36.24s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 183/300 [1:50:00<1:10:09, 35.98s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 184/300 [1:50:35<1:09:06, 35.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 185/300 [1:51:11<1:08:31, 35.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 186/300 [1:51:45<1:07:23, 35.47s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 187/300 [1:52:20<1:06:33, 35.34s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 188/300 [1:52:59<1:07:33, 36.19s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 189/300 [1:53:35<1:06:50, 36.13s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 190/300 [1:54:11<1:06:11, 36.10s/it]                                                      63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 190/300 [1:54:11<1:06:11, 36.10s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 191/300 [1:54:45<1:04:38, 35.59s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 192/300 [1:55:20<1:03:50, 35.47s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 193/300 [1:55:57<1:03:56, 35.85s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 194/300 [1:56:32<1:03:05, 35.72s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 195/300 [1:57:08<1:02:12, 35.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 196/300 [1:57:44<1:02:10, 35.87s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 197/300 [1:58:20<1:01:40, 35.92s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 198/300 [1:58:56<1:00:47, 35.76s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 199/300 [1:59:31<59:49, 35.54s/it]   67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 200/300 [2:00:08<59:57, 35.98s/it]                                                    67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 200/300 [2:00:08<59:57, 35.98s/it]{'eval_loss': 0.9688875079154968, 'eval_runtime': 8.5676, 'eval_samples_per_second': 23.344, 'eval_steps_per_second': 2.918, 'epoch': 21.92}
{'loss': 0.8253, 'learning_rate': 0.00021449999999999998, 'epoch': 23.38}
{'loss': 0.7549, 'learning_rate': 0.0001995, 'epoch': 24.84}
{'loss': 0.7031, 'learning_rate': 0.00018449999999999999, 'epoch': 26.3}
{'loss': 0.6506, 'learning_rate': 0.00016949999999999997, 'epoch': 27.76}
{'loss': 0.5883, 'learning_rate': 0.0001545, 'epoch': 29.22}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.30it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.15it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:05,  3.99it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.93it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.49it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:05,  3.05it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:06,  2.78it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.89it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:03<00:04,  3.04it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:04,  2.82it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  2.72it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.92it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  3.03it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  2.92it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:02,  3.08it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.22it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.20it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:05<00:01,  3.10it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.20it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.24it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:06<00:01,  2.98it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.78it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  2.60it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.53it/s][A                                                   
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 200/300 [2:00:16<59:57, 35.98s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.53it/s][A
                                               [A/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 201/300 [2:00:51<1:03:04, 38.23s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 202/300 [2:01:26<1:00:42, 37.17s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 203/300 [2:02:03<1:00:07, 37.19s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 204/300 [2:02:39<58:52, 36.79s/it]   68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 205/300 [2:03:15<57:55, 36.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 206/300 [2:03:52<57:38, 36.80s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 207/300 [2:04:27<56:15, 36.30s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 208/300 [2:05:04<55:51, 36.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 209/300 [2:05:42<55:59, 36.91s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 210/300 [2:06:16<53:48, 35.87s/it]                                                    70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 210/300 [2:06:16<53:48, 35.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 211/300 [2:06:51<53:05, 35.79s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 212/300 [2:07:27<52:40, 35.91s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 213/300 [2:08:04<52:12, 36.00s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 214/300 [2:08:37<50:16, 35.08s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 215/300 [2:09:12<50:00, 35.30s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 216/300 [2:09:49<49:46, 35.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 217/300 [2:10:23<48:46, 35.26s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 218/300 [2:10:59<48:30, 35.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 219/300 [2:11:36<48:20, 35.81s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 220/300 [2:12:11<47:32, 35.66s/it]                                                    73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 220/300 [2:12:11<47:32, 35.66s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 221/300 [2:12:48<47:34, 36.13s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 222/300 [2:13:24<46:57, 36.12s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 223/300 [2:14:01<46:26, 36.18s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 224/300 [2:14:37<45:45, 36.13s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 225/300 [2:15:11<44:31, 35.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 226/300 [2:15:48<44:13, 35.85s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 227/300 [2:16:25<44:11, 36.33s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 228/300 [2:17:01<43:38, 36.37s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 229/300 [2:17:35<42:07, 35.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 230/300 [2:18:11<41:43, 35.77s/it]                                                    77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 230/300 [2:18:11<41:43, 35.77s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 231/300 [2:18:46<40:47, 35.46s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 232/300 [2:19:21<39:55, 35.22s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 233/300 [2:19:56<39:28, 35.35s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 234/300 [2:20:33<39:18, 35.74s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 235/300 [2:21:10<39:04, 36.07s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 236/300 [2:21:44<37:56, 35.57s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 237/300 [2:22:20<37:21, 35.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 238/300 [2:22:54<36:22, 35.20s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 239/300 [2:23:29<35:32, 34.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 240/300 [2:24:05<35:23, 35.40s/it]                                                    80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 240/300 [2:24:05<35:23, 35.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 241/300 [2:24:41<34:56, 35.53s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 242/300 [2:25:18<34:42, 35.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 243/300 [2:25:53<33:57, 35.75s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 244/300 [2:26:28<33:00, 35.37s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 245/300 [2:27:04<32:43, 35.71s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 246/300 [2:27:40<32:14, 35.83s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 247/300 [2:28:16<31:32, 35.71s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 248/300 [2:28:51<30:50, 35.59s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 249/300 [2:29:26<30:13, 35.55s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 250/300 [2:30:04<30:13, 36.27s/it]                                                    83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 250/300 [2:30:04<30:13, 36.27s/it]{'eval_loss': 0.8252734541893005, 'eval_runtime': 8.5621, 'eval_samples_per_second': 23.359, 'eval_steps_per_second': 2.92, 'epoch': 29.22}
{'loss': 0.5335, 'learning_rate': 0.0001395, 'epoch': 30.68}
{'loss': 0.4771, 'learning_rate': 0.0001245, 'epoch': 32.15}
{'loss': 0.4369, 'learning_rate': 0.00010949999999999999, 'epoch': 33.61}
{'loss': 0.4053, 'learning_rate': 9.449999999999999e-05, 'epoch': 35.07}
{'loss': 0.3689, 'learning_rate': 7.95e-05, 'epoch': 36.53}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.29it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.15it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:05,  4.02it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.98it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.57it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:05,  3.09it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:06,  2.77it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.88it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:02<00:04,  3.05it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:04,  2.86it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  2.75it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.95it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  3.06it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  2.93it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:02,  3.09it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.23it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.21it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:05<00:01,  3.08it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.16it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.17it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:06<00:01,  2.96it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.76it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  2.56it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.55it/s][A                                                   
                                               [A 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 250/300 [2:30:13<30:13, 36.27s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.55it/s][A
                                               [A/home3/p306726/stanford_alpaca/ownenv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 251/300 [2:30:47<31:16, 38.29s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 252/300 [2:31:23<29:53, 37.37s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 253/300 [2:31:59<29:09, 37.23s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 254/300 [2:32:34<27:49, 36.30s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 255/300 [2:33:10<27:11, 36.25s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 256/300 [2:33:45<26:28, 36.11s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 257/300 [2:34:20<25:38, 35.77s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 258/300 [2:34:56<25:05, 35.84s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 259/300 [2:35:32<24:28, 35.81s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 260/300 [2:36:09<23:59, 35.98s/it]                                                    87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 260/300 [2:36:09<23:59, 35.98s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 261/300 [2:36:44<23:16, 35.80s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 262/300 [2:37:18<22:21, 35.30s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 263/300 [2:37:54<21:54, 35.54s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 264/300 [2:38:30<21:21, 35.60s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 265/300 [2:39:05<20:35, 35.30s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 266/300 [2:39:40<20:05, 35.46s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 267/300 [2:40:17<19:38, 35.71s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 268/300 [2:40:51<18:49, 35.28s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 269/300 [2:41:29<18:39, 36.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 270/300 [2:42:04<17:51, 35.73s/it]                                                    90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 270/300 [2:42:04<17:51, 35.73s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 271/300 [2:42:39<17:07, 35.43s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 272/300 [2:43:14<16:34, 35.51s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 273/300 [2:43:49<15:50, 35.19s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 274/300 [2:44:25<15:27, 35.67s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 275/300 [2:45:03<15:04, 36.17s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 276/300 [2:45:38<14:19, 35.82s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 277/300 [2:46:14<13:43, 35.80s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 278/300 [2:46:50<13:09, 35.87s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 279/300 [2:47:26<12:36, 36.01s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 280/300 [2:48:01<11:56, 35.83s/it]                                                    93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 280/300 [2:48:01<11:56, 35.83s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 281/300 [2:48:38<11:27, 36.17s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 282/300 [2:49:13<10:42, 35.71s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 283/300 [2:49:49<10:07, 35.74s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 284/300 [2:50:23<09:25, 35.33s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 285/300 [2:50:58<08:46, 35.13s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 286/300 [2:51:35<08:21, 35.85s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 287/300 [2:52:12<07:47, 35.97s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 288/300 [2:52:47<07:09, 35.77s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 289/300 [2:53:24<06:37, 36.17s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 290/300 [2:54:00<06:02, 36.24s/it]                                                    97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 290/300 [2:54:00<06:02, 36.24s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 291/300 [2:54:37<05:26, 36.26s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 292/300 [2:55:12<04:46, 35.83s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 293/300 [2:55:45<04:06, 35.25s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 294/300 [2:56:22<03:33, 35.51s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 295/300 [2:56:58<02:59, 35.94s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 296/300 [2:57:34<02:23, 35.79s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 297/300 [2:58:08<01:45, 35.14s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 298/300 [2:58:45<01:11, 35.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 299/300 [2:59:20<00:35, 35.54s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [2:59:57<00:00, 36.08s/it]                                                   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [2:59:57<00:00, 36.08s/it]{'eval_loss': 0.7015302777290344, 'eval_runtime': 8.5469, 'eval_samples_per_second': 23.4, 'eval_steps_per_second': 2.925, 'epoch': 36.53}
{'loss': 0.3456, 'learning_rate': 6.45e-05, 'epoch': 37.99}
{'loss': 0.326, 'learning_rate': 4.95e-05, 'epoch': 39.45}
{'loss': 0.3069, 'learning_rate': 3.45e-05, 'epoch': 40.91}
{'loss': 0.2971, 'learning_rate': 1.95e-05, 'epoch': 42.37}
{'loss': 0.2833, 'learning_rate': 4.499999999999999e-06, 'epoch': 43.84}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:03,  6.29it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:05,  4.15it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:05,  4.02it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:05,  3.99it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.62it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:01<00:05,  3.19it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:05,  2.92it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:05,  2.98it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:02<00:04,  3.09it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:05,  2.78it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  2.63it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:04,  2.82it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  2.94it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  2.83it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:05<00:03,  2.99it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.13it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.07it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:06<00:01,  3.02it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.16it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.23it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:07<00:00,  3.01it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  2.86it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  2.72it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.66it/s][A                                                   
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [3:00:06<00:00, 36.08s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.66it/s][A
                                               [A                                                   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [3:00:06<00:00, 36.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [3:00:06<00:00, 36.02s/it]
{'eval_loss': 0.6475167274475098, 'eval_runtime': 8.5034, 'eval_samples_per_second': 23.52, 'eval_steps_per_second': 2.94, 'epoch': 43.84}
{'train_runtime': 10806.2236, 'train_samples_per_second': 3.554, 'train_steps_per_second': 0.028, 'train_loss': 1.039830310344696, 'epoch': 43.84}

###############################################################################
HÃ¡brÃ³k Cluster
Job 3100025 for user 'p306726'
Finished at: Wed Jul 19 07:44:16 CEST 2023

Job details:
============

Job ID              : 3100025
Name                : jobscript.sh
User                : p306726
Partition           : gpushort
Nodes               : a100gpu6
Number of Nodes     : 1
Cores               : 1
Number of Tasks     : 1
State               : COMPLETED
Submit              : 2023-07-19T00:48:05
Start               : 2023-07-19T04:43:07
End                 : 2023-07-19T07:44:16
Reserved walltime   : 04:00:00
Used walltime       : 03:01:09
Used CPU time       : 03:00:07 (efficiency: 99.43%)
% User (Computation): 99.90%
% System (I/O)      :  0.10%
Mem reserved        : 320G
Max Mem (Node/step) : 3.15G (a100gpu6, per node)
Full Max Mem usage  : 3.15G
Total Disk Read     : 723.95M
Total Disk Write    : 857.73M

Acknowledgements:
=================

Please see this page for information about acknowledging HÃ¡brÃ³k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
